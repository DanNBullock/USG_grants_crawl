{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a995a5",
   "metadata": {},
   "source": [
    "# USG grants crawl\n",
    "## Word Tokens\n",
    "\n",
    "### Previously\n",
    "\n",
    "In the previous chapter we loaded the [grants.gov](https://www.grants.gov/web/grants) grants database and looked at some summary characteristics of what it conatined.\n",
    "\n",
    "In this chapter we'll move on to looking at the available data with the goal of learning more about how government grant solicitations might be targeting open Science\n",
    "\n",
    "### Loading the database once more\n",
    "\n",
    "Let's begin by loading up the database provided by the website, which is stored in an xml format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9cf4074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary conversion successful\n",
      "\n",
      "70330 grant entries found, totalling 256.2 MB\n",
      "\n",
      " and with dictionary keys:\n",
      "\n",
      "dict_keys(['OpportunityID', 'OpportunityTitle', 'OpportunityNumber', 'OpportunityCategory', 'FundingInstrumentType', 'CategoryOfFundingActivity', 'CategoryExplanation', 'CFDANumbers', 'EligibleApplicants', 'AdditionalInformationOnEligibility', 'AgencyCode', 'AgencyName', 'PostDate', 'CloseDate', 'LastUpdatedDate', 'AwardCeiling', 'AwardFloor', 'EstimatedTotalProgramFunding', 'ExpectedNumberOfAwards', 'Description', 'Version', 'CostSharingOrMatchingRequirement', 'ArchiveDate', 'GrantorContactEmail', 'GrantorContactEmailDescription', 'GrantorContactText'])\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import xmltodict\n",
    "import sys\n",
    "\n",
    "# FUTURE NOTE: it may be possible to do a check for a local file meeting the relevant criterion and conditionally \n",
    "# download from https://www.grants.gov/extract/ (and extract compressed file) in the event a local target isn't found.\n",
    "# For the moment though...\n",
    "\n",
    "# load up the xml file; hard-path to local file.  Adjust as necessary\n",
    "pathToXML='C://Users//dbullock//Documents//code//gitDir//USG_grants_crawl//inputData//GrantsDBExtract20230113v2.xml'\n",
    "\n",
    "# open and parse file\n",
    "with open(pathToXML, 'r') as f:\n",
    "    govGrantData_raw = f.read()\n",
    "\n",
    "# convert xml to dictionary\n",
    "with open(pathToXML) as xml_file:\n",
    "    govGrantData_dictionary = xmltodict.parse(xml_file.read())\n",
    "\n",
    "# quick size legibility function generated by code-davinci-002\n",
    "def convert_bytes(bytes):\n",
    "    if bytes < 1024:\n",
    "        return str(bytes) + \" B\"\n",
    "    elif bytes < 1048576:\n",
    "        return str(round(bytes/1024, 1)) + \" KB\"\n",
    "    elif bytes < 1073741824:\n",
    "        return str(round(bytes/1048576, 1)) + \" MB\"\n",
    "    elif bytes < 1099511627776:\n",
    "        return str(round(bytes/1073741824, 1)) + \" GB\"\n",
    "    else:\n",
    "        return str(round(bytes/1099511627776, 1)) + \" TB\"\n",
    "    \n",
    "# terminal reports\n",
    "print('Dictionary conversion successful')\n",
    "print('\\n' + str(len(govGrantData_dictionary['Grants']['OpportunitySynopsisDetail_1_0'])) + ' grant entries found, totalling '+ convert_bytes(sys.getsizeof(govGrantData_raw)))\n",
    "#print('\\n and with dictionary keys:\\n')\n",
    "#print(govGrantData_dictionary['Grants']['OpportunitySynopsisDetail_1_0'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "44b62a8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 25.9 GiB for an array with shape (3006099,) and data type <U2311",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [184]\u001b[0m, in \u001b[0;36m<cell line: 44>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m allWordsList\u001b[38;5;241m=\u001b[39momnibusWordBag\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m#do the counting\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m unique_elements, counts_elements \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mallWordsList\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m wordCountsDF\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39masarray([unique_elements,counts_elements])\u001b[38;5;241m.\u001b[39mT,columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwords\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcounts\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m#show it\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:270\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_unique_dispatcher)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(ar, return_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    140\u001b[0m            return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m    Find the unique elements of an array.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    268\u001b[0m \n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m     ar \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    272\u001b[0m         ret \u001b[38;5;241m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 25.9 GiB for an array with shape (3006099,) and data type <U2311"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# ok we can also try and use these co occurances to threshold the grants and find other shared words\n",
    "\n",
    "grantIDholder=[]\n",
    "# begin by using the same code as above to identify grants which occur more than a certian number of times\n",
    "for iIndexX, iKeywordsX in enumerate(list(grantFindsOut.keys())):\n",
    "        # get the values for each \"node\" (e.g. the grant IDs for each keyword)\n",
    "        IDsX=grantFindsOut[iKeywordsX]\n",
    "        grantIDholder.extend(IDsX)\n",
    "\n",
    "# now that we have a vector with those ID's let's get the description content\n",
    "\n",
    "#actually, we first have to get a list of the grant IDs\n",
    "allGrantIDs=[]\n",
    "for iListing in govGrantData_dictionary['Grants']['OpportunitySynopsisDetail_1_0']:\n",
    "    allGrantIDs.append(iListing['OpportunityID'])\n",
    "\n",
    "#create a holder\n",
    "grantDescriptions=[]\n",
    "\n",
    "for iGrantIDs in grantIDholder:\n",
    "    currentGrantIndex=allGrantIDs.index(iGrantIDs)\n",
    "    currentDescription=govGrantData_dictionary['Grants']['OpportunitySynopsisDetail_1_0'][currentGrantIndex]['Description']\n",
    "    grantDescriptions.append(currentDescription.lower())\n",
    "    \n",
    "omnibusWordBag=' '.join(grantDescriptions)\n",
    "\n",
    "tokenizedWords = re.sub(r\"[^a-zA-Z0-9]\", \" \", omnibusWordBag.lower()).split()\n",
    "\n",
    "# load the stopword bag\n",
    "with open('stopwords.txt') as f:\n",
    "    stopwords = f.read()\n",
    "\n",
    "# iterate through the stopwords bag\n",
    "for iStopwords in stopwords.split('\\n'):\n",
    "    iStopwords\n",
    "    omnibusWordBag=omnibusWordBag.replace(' '+iStopwords+' ',' ')\n",
    "    omnibusWordBag=omnibusWordBag.replace(' '+iStopwords+'.','')\n",
    "    \n",
    "# split the bag of words into individual words\n",
    "allWordsList=omnibusWordBag.split(' ')\n",
    "\n",
    "#do the counting\n",
    "unique_elements, counts_elements = np.unique(allWordsList, return_counts=True)\n",
    "wordCountsDF=pd.DataFrame(np.asarray([unique_elements,counts_elements]).T,columns=['words','counts'])\n",
    "#show it\n",
    "itables.show(wordCountsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1d46e0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 119,  154,  524,    1,   37,   66,   60,   23, 1471,    7,  163,\n",
       "          0,  118,    0,  267,  392,   20,  226,   67,   63, 3626,    9,\n",
       "        474,  856, 3237,  400,   66,    0])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray([len(grantFindsOut[iKeyword]) for iKeyword in grantFindsOut.keys()]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2470f5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'national',\n",
       " 'historical',\n",
       " 'publications',\n",
       " 'and',\n",
       " 'records',\n",
       " 'commission',\n",
       " 'seeks',\n",
       " 'proposals',\n",
       " 'that',\n",
       " 'use',\n",
       " 'cost',\n",
       " 'effective',\n",
       " 'methods',\n",
       " 'to',\n",
       " 'digitize',\n",
       " 'nationally',\n",
       " 'significant',\n",
       " 'historical',\n",
       " 'record',\n",
       " 'collections',\n",
       " 'and',\n",
       " 'make',\n",
       " 'the',\n",
       " 'digital',\n",
       " 'versions',\n",
       " 'freely',\n",
       " 'available',\n",
       " 'online',\n",
       " 'projects',\n",
       " 'must',\n",
       " 'make',\n",
       " 'use',\n",
       " 'of',\n",
       " 'existing',\n",
       " 'holdings',\n",
       " 'of',\n",
       " 'historical',\n",
       " 'repositories',\n",
       " 'and',\n",
       " 'consist',\n",
       " 'of',\n",
       " 'entire',\n",
       " 'collections',\n",
       " 'or',\n",
       " 'series',\n",
       " 'the',\n",
       " 'materials',\n",
       " 'should',\n",
       " 'already',\n",
       " 'be',\n",
       " 'available',\n",
       " 'to',\n",
       " 'the',\n",
       " 'public',\n",
       " 'at',\n",
       " 'the',\n",
       " 'archives',\n",
       " 'and',\n",
       " 'described',\n",
       " 'so',\n",
       " 'that',\n",
       " 'projects',\n",
       " 'can',\n",
       " 're',\n",
       " 'use',\n",
       " 'existing',\n",
       " 'information',\n",
       " 'to',\n",
       " 'serve',\n",
       " 'as',\n",
       " 'metadata',\n",
       " 'for',\n",
       " 'the',\n",
       " 'digitized',\n",
       " 'collection',\n",
       " 'to',\n",
       " 'make',\n",
       " 'these',\n",
       " 'projects',\n",
       " 'as',\n",
       " 'widely',\n",
       " 'useful',\n",
       " 'as',\n",
       " 'possible',\n",
       " 'for',\n",
       " 'archives',\n",
       " 'historical',\n",
       " 'repositories',\n",
       " 'and',\n",
       " 'researchers',\n",
       " 'the',\n",
       " 'applications',\n",
       " 'must',\n",
       " 'demonstrate',\n",
       " '1',\n",
       " 'the',\n",
       " 'national',\n",
       " 'significance',\n",
       " 'of',\n",
       " 'the',\n",
       " 'collections',\n",
       " 'or',\n",
       " 'records',\n",
       " 'series',\n",
       " 'to',\n",
       " 'be',\n",
       " 'digitized',\n",
       " '2',\n",
       " 'an',\n",
       " 'effective',\n",
       " 'work',\n",
       " 'flow',\n",
       " 'that',\n",
       " 'repurposes',\n",
       " 'existing',\n",
       " 'descriptive',\n",
       " 'material',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'creating',\n",
       " 'new',\n",
       " 'metadata',\n",
       " 'about',\n",
       " 'the',\n",
       " 'records',\n",
       " '3',\n",
       " 'reasonable',\n",
       " 'costs',\n",
       " 'and',\n",
       " 'standards',\n",
       " 'for',\n",
       " 'the',\n",
       " 'project',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'sustainable',\n",
       " 'preservation',\n",
       " 'plans',\n",
       " 'for',\n",
       " 'the',\n",
       " 'resulting',\n",
       " 'digital',\n",
       " 'records',\n",
       " '4',\n",
       " 'well',\n",
       " 'designed',\n",
       " 'plans',\n",
       " 'that',\n",
       " 'evaluate',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'the',\n",
       " 'digitized',\n",
       " 'materials',\n",
       " 'and',\n",
       " 'the',\n",
       " 'effectiveness',\n",
       " 'of',\n",
       " 'the',\n",
       " 'methods',\n",
       " 'employed',\n",
       " 'in',\n",
       " 'digitizing',\n",
       " 'and',\n",
       " 'displaying',\n",
       " 'the',\n",
       " 'materials',\n",
       " 'projects',\n",
       " 'may',\n",
       " 'not',\n",
       " 'use',\n",
       " 'grant',\n",
       " 'funds',\n",
       " 'to',\n",
       " 'create',\n",
       " 'descriptive',\n",
       " 'metadata',\n",
       " 'or',\n",
       " 'edited',\n",
       " 'transcriptions',\n",
       " 'of',\n",
       " 'the',\n",
       " 'digitized',\n",
       " 'materials',\n",
       " 'or',\n",
       " 'develop',\n",
       " 'websites',\n",
       " 'where',\n",
       " 'people',\n",
       " 'will',\n",
       " 'have',\n",
       " 'to',\n",
       " 'pay',\n",
       " 'a',\n",
       " 'fee',\n",
       " 'to',\n",
       " 'view',\n",
       " 'the',\n",
       " 'images',\n",
       " 'for',\n",
       " 'a',\n",
       " 'comprehensive',\n",
       " 'list',\n",
       " 'of',\n",
       " 'commission',\n",
       " 'limitations',\n",
       " 'on',\n",
       " 'funding',\n",
       " 'please',\n",
       " 'see',\n",
       " '147',\n",
       " 'what',\n",
       " 'we',\n",
       " 'do',\n",
       " 'and',\n",
       " 'do',\n",
       " 'not',\n",
       " 'fund',\n",
       " '148',\n",
       " 'http',\n",
       " 'www',\n",
       " 'archives',\n",
       " 'gov',\n",
       " 'nhprc',\n",
       " 'apply',\n",
       " 'eligibility',\n",
       " 'html',\n",
       " 'a',\n",
       " 'grant',\n",
       " 'normally',\n",
       " 'is',\n",
       " 'for',\n",
       " 'one',\n",
       " 'to',\n",
       " 'three',\n",
       " 'years',\n",
       " 'and',\n",
       " 'up',\n",
       " 'to',\n",
       " '150',\n",
       " '000',\n",
       " 'the',\n",
       " 'commission',\n",
       " 'expects',\n",
       " 'to',\n",
       " 'make',\n",
       " 'up',\n",
       " 'to',\n",
       " '8',\n",
       " 'grants',\n",
       " 'in',\n",
       " 'this',\n",
       " 'category',\n",
       " 'for',\n",
       " 'a',\n",
       " 'total',\n",
       " 'of',\n",
       " 'up',\n",
       " 'to',\n",
       " '700',\n",
       " '000',\n",
       " 'the',\n",
       " 'commission',\n",
       " 'requires',\n",
       " 'that',\n",
       " 'grant',\n",
       " 'recipients',\n",
       " 'acknowledge',\n",
       " 'nhprc',\n",
       " 'grant',\n",
       " 'assistance',\n",
       " 'in',\n",
       " 'all',\n",
       " 'products',\n",
       " 'that',\n",
       " 'result',\n",
       " 'from',\n",
       " 'its',\n",
       " 'support',\n",
       " 'eligible',\n",
       " 'applicants',\n",
       " 'nonprofit',\n",
       " 'organizations',\n",
       " 'or',\n",
       " 'institutions',\n",
       " 'colleges',\n",
       " 'universities',\n",
       " 'and',\n",
       " 'other',\n",
       " 'academic',\n",
       " 'institutions',\n",
       " 'state',\n",
       " 'or',\n",
       " 'local',\n",
       " 'government',\n",
       " 'agencies',\n",
       " 'federally',\n",
       " 'acknowledged',\n",
       " 'or',\n",
       " 'state',\n",
       " 'recognized',\n",
       " 'native',\n",
       " 'american',\n",
       " 'tribes',\n",
       " 'or',\n",
       " 'groups',\n",
       " 'applicant',\n",
       " 'organizations',\n",
       " 'must',\n",
       " 'be',\n",
       " 'registered',\n",
       " 'in',\n",
       " 'central',\n",
       " 'contractor',\n",
       " 'registration',\n",
       " 'ccr',\n",
       " 'prior',\n",
       " 'to',\n",
       " 'submitting',\n",
       " 'an',\n",
       " 'application',\n",
       " 'maintain',\n",
       " 'ccr',\n",
       " 'registration',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'application',\n",
       " 'and',\n",
       " 'award',\n",
       " 'process',\n",
       " 'and',\n",
       " 'include',\n",
       " 'a',\n",
       " 'valid',\n",
       " 'duns',\n",
       " 'number',\n",
       " 'in',\n",
       " 'their',\n",
       " 'application',\n",
       " 'details',\n",
       " 'on',\n",
       " 'ccr',\n",
       " 'registration',\n",
       " 'and',\n",
       " 'requesting',\n",
       " 'a',\n",
       " 'duns',\n",
       " 'number',\n",
       " 'can',\n",
       " 'be',\n",
       " 'found',\n",
       " 'at',\n",
       " 'the',\n",
       " 'central',\n",
       " 'contractor',\n",
       " 'registration',\n",
       " 'website',\n",
       " 'ineligible',\n",
       " 'applications',\n",
       " 'will',\n",
       " 'not',\n",
       " 'be',\n",
       " 'considered',\n",
       " 'cost',\n",
       " 'sharing',\n",
       " 'is',\n",
       " 'required',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the',\n",
       " 'financial',\n",
       " 'contribution',\n",
       " 'the',\n",
       " 'applicant',\n",
       " 'pledges',\n",
       " 'to',\n",
       " 'the',\n",
       " 'cost',\n",
       " 'of',\n",
       " 'a',\n",
       " 'project',\n",
       " 'cost',\n",
       " 'sharing',\n",
       " 'can',\n",
       " 'include',\n",
       " 'both',\n",
       " 'direct',\n",
       " 'and',\n",
       " 'indirect',\n",
       " 'expenses',\n",
       " 'in',\n",
       " 'kind',\n",
       " 'contributions',\n",
       " 'non',\n",
       " 'federal',\n",
       " 'third',\n",
       " 'party',\n",
       " 'contributions',\n",
       " 'and',\n",
       " 'any',\n",
       " 'income',\n",
       " 'earned',\n",
       " 'directly',\n",
       " 'by',\n",
       " 'the',\n",
       " 'project',\n",
       " 'the',\n",
       " 'nhprc',\n",
       " 'will',\n",
       " 'provide',\n",
       " 'up',\n",
       " 'to',\n",
       " '50',\n",
       " 'percent',\n",
       " 'of',\n",
       " 'the',\n",
       " 'total',\n",
       " 'project',\n",
       " 'costs',\n",
       " 'the',\n",
       " 'purpose',\n",
       " 'of',\n",
       " 'this',\n",
       " 'funding',\n",
       " 'opportunity',\n",
       " 'announcement',\n",
       " 'foa',\n",
       " 'is',\n",
       " 'to',\n",
       " 'identify',\n",
       " 'and',\n",
       " 'support',\n",
       " 'a',\n",
       " 'four',\n",
       " 'dimensional',\n",
       " 'nucleome',\n",
       " '4dn',\n",
       " 'network',\n",
       " 'data',\n",
       " 'coordination',\n",
       " 'and',\n",
       " 'integration',\n",
       " 'center',\n",
       " 'dcic',\n",
       " 'the',\n",
       " 'overarching',\n",
       " 'mission',\n",
       " 'of',\n",
       " '4dn',\n",
       " 'dcic',\n",
       " 'will',\n",
       " 'be',\n",
       " 'to',\n",
       " 'collect',\n",
       " 'store',\n",
       " 'curate',\n",
       " 'and',\n",
       " 'display',\n",
       " 'all',\n",
       " 'data',\n",
       " 'metadata',\n",
       " 'and',\n",
       " 'analysis',\n",
       " 'tools',\n",
       " 'generated',\n",
       " 'by',\n",
       " 'the',\n",
       " '4dn',\n",
       " 'network',\n",
       " 'the',\n",
       " 'dcic',\n",
       " 'will',\n",
       " 'also',\n",
       " 'assist',\n",
       " 'in',\n",
       " 'the',\n",
       " 'development',\n",
       " 'and',\n",
       " 'dissemination',\n",
       " 'of',\n",
       " 'metadata',\n",
       " 'and',\n",
       " 'standards',\n",
       " 'to',\n",
       " 'be',\n",
       " 'adopted',\n",
       " 'by',\n",
       " 'the',\n",
       " 'community',\n",
       " 'at',\n",
       " 'large',\n",
       " 'approaches',\n",
       " 'for',\n",
       " 'integrative',\n",
       " 'analysis',\n",
       " 'of',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'range',\n",
       " 'of',\n",
       " 'data',\n",
       " 'types',\n",
       " 'and',\n",
       " 'visualization',\n",
       " 'and',\n",
       " 'analysis',\n",
       " 'tools',\n",
       " 'to',\n",
       " 'facilitate',\n",
       " 'access',\n",
       " 'and',\n",
       " 'understanding',\n",
       " 'of',\n",
       " 'complex',\n",
       " 'datasets',\n",
       " 'to',\n",
       " 'non',\n",
       " 'expert',\n",
       " 'users',\n",
       " 'the',\n",
       " 'tasks',\n",
       " 'to',\n",
       " 'be',\n",
       " 'performed',\n",
       " 'under',\n",
       " 'this',\n",
       " 'agreement',\n",
       " 'are',\n",
       " 'as',\n",
       " 'follows',\n",
       " '1',\n",
       " 'processing',\n",
       " 'the',\n",
       " 'existing',\n",
       " 'elk',\n",
       " 'gps',\n",
       " 'collar',\n",
       " 'data',\n",
       " 'set',\n",
       " 'to',\n",
       " 'exclude',\n",
       " 'pre',\n",
       " 'deployment',\n",
       " 'fixes',\n",
       " 'erroneous',\n",
       " 'fixes',\n",
       " 'and',\n",
       " 'post',\n",
       " 'mortality',\n",
       " 'or',\n",
       " 'post',\n",
       " 'collar',\n",
       " 'drop',\n",
       " 'fixes',\n",
       " 'ner',\n",
       " 'will',\n",
       " 'provide',\n",
       " 'metadata',\n",
       " 'that',\n",
       " 'includes',\n",
       " 'deployment',\n",
       " 'and',\n",
       " 'offair',\n",
       " 'dates',\n",
       " 'that',\n",
       " 'should',\n",
       " 'facilitate',\n",
       " 'this',\n",
       " 'process',\n",
       " '2',\n",
       " 'creating',\n",
       " 'a',\n",
       " 'merged',\n",
       " 'geodatabase',\n",
       " 'or',\n",
       " 'shapfile',\n",
       " 'that',\n",
       " 'includes',\n",
       " 'elk',\n",
       " 'id',\n",
       " 'as',\n",
       " 'a',\n",
       " 'field',\n",
       " '3',\n",
       " 'descriptive',\n",
       " 'summaries',\n",
       " 'for',\n",
       " 'each',\n",
       " 'elk',\n",
       " 'documenting',\n",
       " 'summer',\n",
       " 'range',\n",
       " 'ner',\n",
       " 'arrival',\n",
       " 'and',\n",
       " 'departure',\n",
       " 'times',\n",
       " 'etc',\n",
       " 'this',\n",
       " 'information',\n",
       " 'is',\n",
       " 'useful',\n",
       " 'for',\n",
       " 'planning',\n",
       " 'hunt',\n",
       " 'seasons',\n",
       " 'and',\n",
       " 'assessing',\n",
       " 'the',\n",
       " 'timing',\n",
       " 'of',\n",
       " 'seasonal',\n",
       " 'closures',\n",
       " 'on',\n",
       " 'the',\n",
       " 'bike',\n",
       " 'path',\n",
       " 'that',\n",
       " 'is',\n",
       " 'adjacent',\n",
       " 'to',\n",
       " 'the',\n",
       " 'refuge',\n",
       " 'the',\n",
       " 'national',\n",
       " 'park',\n",
       " 'service',\n",
       " 'nps',\n",
       " 'is',\n",
       " 'requesting',\n",
       " 'proposals',\n",
       " 'from',\n",
       " 'a',\n",
       " 'potential',\n",
       " 'recipient',\n",
       " 'to',\n",
       " 'collaboratively',\n",
       " 'develop',\n",
       " 'a',\n",
       " 'natural',\n",
       " 'resource',\n",
       " 'condition',\n",
       " 'assessment',\n",
       " 'nrca',\n",
       " 'for',\n",
       " 'haleakala',\n",
       " 'national',\n",
       " 'park',\n",
       " 'located',\n",
       " 'on',\n",
       " 'the',\n",
       " 'island',\n",
       " 'of',\n",
       " 'maui',\n",
       " 'in',\n",
       " 'the',\n",
       " 'state',\n",
       " 'of',\n",
       " 'hawaii',\n",
       " 'the',\n",
       " 'nrca',\n",
       " 'will',\n",
       " 'provide',\n",
       " 'an',\n",
       " 'evaluation',\n",
       " 'of',\n",
       " 'current',\n",
       " 'ecological',\n",
       " 'conditions',\n",
       " 'and',\n",
       " 'discernible',\n",
       " 'trends',\n",
       " 'for',\n",
       " 'natural',\n",
       " 'resources',\n",
       " 'and',\n",
       " 'ecosystem',\n",
       " 'processes',\n",
       " 'identify',\n",
       " 'critical',\n",
       " 'data',\n",
       " 'and',\n",
       " 'knowledge',\n",
       " 'gaps',\n",
       " 'and',\n",
       " 'highlight',\n",
       " 'existing',\n",
       " 'and',\n",
       " 'potential',\n",
       " 'threats',\n",
       " 'to',\n",
       " 'natural',\n",
       " 'resources',\n",
       " 'and',\n",
       " 'ecosystems',\n",
       " 'within',\n",
       " 'the',\n",
       " 'park',\n",
       " 'this',\n",
       " 'assessment',\n",
       " 'will',\n",
       " 'rely',\n",
       " 'on',\n",
       " 'existing',\n",
       " 'scientific',\n",
       " 'data',\n",
       " 'from',\n",
       " 'multiple',\n",
       " 'sources',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'the',\n",
       " 'best',\n",
       " 'professional',\n",
       " 'judgment',\n",
       " 'of',\n",
       " 'an',\n",
       " 'interdisciplinary',\n",
       " 'team',\n",
       " 'of',\n",
       " 'specialists',\n",
       " 'headed',\n",
       " 'by',\n",
       " 'the',\n",
       " 'recipient',\n",
       " 'principal',\n",
       " 'investigator',\n",
       " 'to',\n",
       " 'evaluate',\n",
       " 'current',\n",
       " 'status',\n",
       " 'and',\n",
       " 'suggest',\n",
       " 'future',\n",
       " 'conditions',\n",
       " 'for',\n",
       " 'natural',\n",
       " 'resources',\n",
       " 'in',\n",
       " 'the',\n",
       " 'park',\n",
       " 'the',\n",
       " 'assessment',\n",
       " 'will',\n",
       " 'focus',\n",
       " 'on',\n",
       " 'a',\n",
       " 'subset',\n",
       " 'of',\n",
       " 'terrestrial',\n",
       " 'aquatic',\n",
       " 'and',\n",
       " 'marine',\n",
       " 'resources',\n",
       " 'and',\n",
       " 'processes',\n",
       " 'selected',\n",
       " 'by',\n",
       " 'the',\n",
       " 'park',\n",
       " 'for',\n",
       " 'particular',\n",
       " 'attention',\n",
       " 'products',\n",
       " 'include',\n",
       " 'a',\n",
       " 'final',\n",
       " 'report',\n",
       " 'in',\n",
       " 'a',\n",
       " 'specified',\n",
       " 'format',\n",
       " 'which',\n",
       " 'includes',\n",
       " 'relevant',\n",
       " 'graphs',\n",
       " 'charts',\n",
       " 'and',\n",
       " 'maps',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'separate',\n",
       " 'gis',\n",
       " 'products',\n",
       " 'and',\n",
       " 'associated',\n",
       " 'metadata',\n",
       " 'environmental',\n",
       " 'exposure',\n",
       " 'induced',\n",
       " 'perturbations',\n",
       " 'of',\n",
       " 'epigenomic',\n",
       " 'marks',\n",
       " 'have',\n",
       " 'been',\n",
       " 'correlated',\n",
       " 'with',\n",
       " 'multiple',\n",
       " 'aspects',\n",
       " 'of',\n",
       " 'disease',\n",
       " 'pathogenesis',\n",
       " 'in',\n",
       " '2012',\n",
       " 'the',\n",
       " 'national',\n",
       " 'institute',\n",
       " 'of',\n",
       " 'environmental',\n",
       " 'health',\n",
       " 'sciences',\n",
       " 'established',\n",
       " 'the',\n",
       " 'multi',\n",
       " 'phased',\n",
       " 'toxicant',\n",
       " 'exposures',\n",
       " 'and',\n",
       " 'responses',\n",
       " 'by',\n",
       " 'genomic',\n",
       " 'and',\n",
       " 'epigenomic',\n",
       " 'regulators',\n",
       " 'of',\n",
       " 'transcription',\n",
       " 'target',\n",
       " 'program',\n",
       " 'to',\n",
       " 'further',\n",
       " 'address',\n",
       " 'the',\n",
       " 'role',\n",
       " 'of',\n",
       " 'the',\n",
       " 'environment',\n",
       " 'in',\n",
       " 'disease',\n",
       " 'susceptibility',\n",
       " 'as',\n",
       " 'a',\n",
       " 'function',\n",
       " 'of',\n",
       " 'changes',\n",
       " 'to',\n",
       " 'the',\n",
       " 'epigenome',\n",
       " 'the',\n",
       " 'first',\n",
       " 'phase',\n",
       " 'of',\n",
       " 'this',\n",
       " 'program',\n",
       " 'target',\n",
       " 'i',\n",
       " 'rfa',\n",
       " 'es',\n",
       " '12',\n",
       " '008',\n",
       " 'target',\n",
       " 'i',\n",
       " 'chromatin',\n",
       " 'structure',\n",
       " 'genomics',\n",
       " 'and',\n",
       " 'transcriptional',\n",
       " 'responses',\n",
       " 'to',\n",
       " 'the',\n",
       " 'environment',\n",
       " 'solicited',\n",
       " 'and',\n",
       " 'funded',\n",
       " 'applications',\n",
       " 'pursuing',\n",
       " 'research',\n",
       " 'objectives',\n",
       " 'aimed',\n",
       " 'at',\n",
       " 'understanding',\n",
       " 'environmental',\n",
       " 'influences',\n",
       " 'on',\n",
       " 'epigenetic',\n",
       " 'mechanisms',\n",
       " 'and',\n",
       " 'transcriptional',\n",
       " 'regulation',\n",
       " 'these',\n",
       " 'grants',\n",
       " 'consider',\n",
       " 'the',\n",
       " 'impact',\n",
       " 'of',\n",
       " 'environmental',\n",
       " 'toxicants',\n",
       " 'on',\n",
       " 'the',\n",
       " 'following',\n",
       " 'processes',\n",
       " 'nucleosome',\n",
       " 'positioning',\n",
       " 'chromatin',\n",
       " 'accessibility',\n",
       " 'chromatin',\n",
       " 'remodeling',\n",
       " 'and',\n",
       " 'the',\n",
       " 'role',\n",
       " 'of',\n",
       " 'non',\n",
       " 'coding',\n",
       " 'rnas',\n",
       " 'the',\n",
       " 'niehs',\n",
       " 'has',\n",
       " 'also',\n",
       " 'awarded',\n",
       " 'a',\n",
       " 'number',\n",
       " 'of',\n",
       " 'unsolicited',\n",
       " 'grants',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past',\n",
       " 'two',\n",
       " 'years',\n",
       " 'with',\n",
       " 'specific',\n",
       " 'aims',\n",
       " 'that',\n",
       " 'are',\n",
       " 'compatible',\n",
       " 'with',\n",
       " 'the',\n",
       " 'stated',\n",
       " 'goals',\n",
       " 'of',\n",
       " 'the',\n",
       " 'target',\n",
       " 'i',\n",
       " 'foa',\n",
       " 'using',\n",
       " 'a',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'model',\n",
       " 'systems',\n",
       " 'however',\n",
       " 'identifying',\n",
       " 'changes',\n",
       " 'in',\n",
       " 'epigenomic',\n",
       " 'marks',\n",
       " 'dna',\n",
       " 'methylation',\n",
       " 'histone',\n",
       " 'modifications',\n",
       " 'chromatin',\n",
       " 'accessibility',\n",
       " 'in',\n",
       " 'tissues',\n",
       " 'cells',\n",
       " 'affected',\n",
       " 'by',\n",
       " 'disease',\n",
       " 'relevant',\n",
       " 'environmental',\n",
       " 'exposures',\n",
       " 'as',\n",
       " 'a',\n",
       " 'research',\n",
       " 'strategy',\n",
       " 'is',\n",
       " 'not',\n",
       " 'always',\n",
       " 'feasible',\n",
       " 'in',\n",
       " 'humans',\n",
       " 'the',\n",
       " 'purpose',\n",
       " 'of',\n",
       " 'this',\n",
       " 'funding',\n",
       " 'opportunity',\n",
       " 'announcement',\n",
       " 'foa',\n",
       " 'is',\n",
       " 'to',\n",
       " 'establish',\n",
       " 'the',\n",
       " 'target',\n",
       " 'data',\n",
       " ...]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizedWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "de5f068c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbullock\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [186]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[0;32m      2\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer()\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:88\u001b[0m, in \u001b[0;36mdeprecated._decorate_fun.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fun)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     87\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1429\u001b[0m, in \u001b[0;36mCountVectorizer.get_feature_names\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;129m@deprecated\u001b[39m(\n\u001b[0;32m   1418\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_feature_names is deprecated in 1.0 and will be removed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1419\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min 1.2. Please use get_feature_names_out instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1420\u001b[0m )\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_feature_names\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1422\u001b[0m     \u001b[38;5;124;03m\"\"\"Array mapping from feature integer indices to feature name.\u001b[39;00m\n\u001b[0;32m   1423\u001b[0m \n\u001b[0;32m   1424\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;124;03m        A list of feature names.\u001b[39;00m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [t \u001b[38;5;28;01mfor\u001b[39;00m t, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocabulary_\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39mitemgetter(\u001b[38;5;241m1\u001b[39m))]\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:498\u001b[0m, in \u001b[0;36m_VectorizerMixin._check_vocabulary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_vocabulary()\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_:\n\u001b[1;32m--> 498\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVocabulary not fitted or provided\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocabulary_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVocabulary is empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c344edc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '000001' ... 'zurab' 'zw' 'zydeco']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1x41687 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 41687 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform([omnibusWordBag])\n",
    "print(vectorizer.get_feature_names_out())\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec76865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
