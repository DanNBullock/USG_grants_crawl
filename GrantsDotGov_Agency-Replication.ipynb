{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a995a5",
   "metadata": {},
   "source": [
    "# USG grants crawl\n",
    "## Agency-specific replication from  Lee & Chung (2022)\n",
    "\n",
    "### Previously\n",
    "\n",
    "In the previous chapter we looked at how often a selected set of open-science infrastructure related terms showed up in [grants.gov](https://www.grants.gov/web/grants) grant descriptions, and which agencies' grants they were showing up in.  \n",
    "\n",
    "The keyword list we used was one of our own making.  However, we are certianly not the first to explore this topic.  Indeed [Lee & Chung (2022)](https://doi.org/10.47989/irpaper949) looked precisely at the question of what keywords were most associated with this topic.  We can use their keywords and replicate our previous analysis using the expanded and empirically supported list of words.  This only involves minor changes to the previous noteook.\n",
    "\n",
    "### Loading the database once more\n",
    "\n",
    "Let's begin by loading up the database provided by the website, which is stored in an xml format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9cf4074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary conversion successful\n",
      "\n",
      "70330 grant entries found, totalling 256.2 MB\n",
      "\n",
      " and with dictionary keys:\n",
      "\n",
      "dict_keys(['OpportunityID', 'OpportunityTitle', 'OpportunityNumber', 'OpportunityCategory', 'FundingInstrumentType', 'CategoryOfFundingActivity', 'CategoryExplanation', 'CFDANumbers', 'EligibleApplicants', 'AdditionalInformationOnEligibility', 'AgencyCode', 'AgencyName', 'PostDate', 'CloseDate', 'LastUpdatedDate', 'AwardCeiling', 'AwardFloor', 'EstimatedTotalProgramFunding', 'ExpectedNumberOfAwards', 'Description', 'Version', 'CostSharingOrMatchingRequirement', 'ArchiveDate', 'GrantorContactEmail', 'GrantorContactEmailDescription', 'GrantorContactText'])\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import xmltodict\n",
    "import sys\n",
    "\n",
    "# FUTURE NOTE: it may be possible to do a check for a local file meeting the relevant criterion and conditionally \n",
    "# download from https://www.grants.gov/extract/ (and extract compressed file) in the event a local target isn't found.\n",
    "# For the moment though...\n",
    "\n",
    "# load up the xml file; hard-path to local file.  Adjust as necessary\n",
    "pathToXML='C://Users//dbullock//Documents//code//gitDir//USG_grants_crawl//inputData//GrantsDBExtract20230113v2.xml'\n",
    "\n",
    "# open and parse file\n",
    "with open(pathToXML, 'r') as f:\n",
    "    govGrantData_raw = f.read()\n",
    "\n",
    "# convert xml to dictionary\n",
    "with open(pathToXML) as xml_file:\n",
    "    govGrantData_dictionary = xmltodict.parse(xml_file.read())\n",
    "\n",
    "# quick size legibility function generated by code-davinci-002\n",
    "def convert_bytes(bytes):\n",
    "    if bytes < 1024:\n",
    "        return str(bytes) + \" B\"\n",
    "    elif bytes < 1048576:\n",
    "        return str(round(bytes/1024, 1)) + \" KB\"\n",
    "    elif bytes < 1073741824:\n",
    "        return str(round(bytes/1048576, 1)) + \" MB\"\n",
    "    elif bytes < 1099511627776:\n",
    "        return str(round(bytes/1073741824, 1)) + \" GB\"\n",
    "    else:\n",
    "        return str(round(bytes/1099511627776, 1)) + \" TB\"\n",
    "    \n",
    "# terminal reports\n",
    "print('Dictionary conversion successful')\n",
    "print('\\n' + str(len(govGrantData_dictionary['Grants']['OpportunitySynopsisDetail_1_0'])) + ' grant entries found, totalling '+ convert_bytes(sys.getsizeof(govGrantData_raw)))\n",
    "print('\\n and with dictionary keys:\\n')\n",
    "print(govGrantData_dictionary['Grants']['OpportunitySynopsisDetail_1_0'][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1f7d27",
   "metadata": {},
   "source": [
    "### Keywords and terms\n",
    "\n",
    "Although we aren't going to inspect the keywords and agencies on their own this time, we still need to collect them.  Once we have loaded them, we can determine which words are occuring in which grants, and which agencies those grants are associated with.  The resulting information can be placed in a dictionary, where the relevant information can be accessed by using the [tuple](https://www.w3schools.com/python/python_tuples.asp) corresponding to the desired agency and keyword (e.g. ('agency','keyword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca37ba50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       categories                    terms\n",
      "0        pre-registrations and registered reports       replication crisis\n",
      "1        pre-registrations and registered reports              methodology\n",
      "2        pre-registrations and registered reports          preregistration\n",
      "3        pre-registrations and registered reports              replication\n",
      "4        pre-registrations and registered reports       registered reports\n",
      "5                                       preprints                preprints\n",
      "6                                       preprints          social sciences\n",
      "7                                 reproducibility          reproducibility\n",
      "8                                 reproducibility             transparency\n",
      "9                                 reproducibility            replicability\n",
      "10                                reproducibility                 COVID-19\n",
      "11                                reproducibility                   ethics\n",
      "12                                reproducibility           journal policy\n",
      "13                                reproducibility            meta-analysis\n",
      "14                                reproducibility            meta-research\n",
      "15                                reproducibility             meta-science\n",
      "16                                reproducibility                 policies\n",
      "17                                reproducibility         research methods\n",
      "18                                    open access              open access\n",
      "19                                    open access  scholarly communication\n",
      "20                                    open access            collaboration\n",
      "21                                    open access              open source\n",
      "22                                    open access      research evaluation\n",
      "23                                    open access     scholarly publishing\n",
      "24                                   data sharing             data sharing\n",
      "25                                   data sharing                open data\n",
      "26                                   data sharing                 big data\n",
      "27                                   data sharing                 metadata\n",
      "28                                  research data          data management\n",
      "29                                  research data                     FAIR\n",
      "30                               open peer review         open peer review\n",
      "31                               open peer review              peer review\n",
      "32  Tools and platforms for reproducible research           bioinformatics\n",
      "33  Tools and platforms for reproducible research    reproducible research\n",
      "34  Tools and platforms for reproducible research             data science\n",
      "35  Tools and platforms for reproducible research                 database\n",
      "36  Tools and platforms for reproducible research                        R\n",
      "37  Tools and platforms for reproducible research                 workflow\n",
      "38                Open innovation, science policy          open innovation\n",
      "39                Open innovation; science policy                 openness\n",
      "40                Open innovation; science policy           science policy\n",
      "41                Open innovation; science policy               innovation\n",
      "42                Open innovation; science policy    intellectual property\n",
      "43                Open innovation; science policy            research data\n",
      "44                Open innovation; science policy       academic libraries\n",
      "45                Open innovation; science policy            bibliometrics\n",
      "46                Open innovation; science policy          citizen science\n",
      "47                Open innovation; science policy             repositories\n",
      "48                Open innovation; science policy                 research\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "#HERE'S THE CHANGE FROM THE PREVOUS NOTEBOOK\n",
    "# open the keywords csv file\n",
    "inputKeywords=pd.read_csv('OSterms_LeeChung2022.csv')\n",
    "print(inputKeywords)\n",
    "\n",
    "# split it into a list.  Each term is kept on a separate line\n",
    "keywords=inputKeywords['terms'].tolist()\n",
    "\n",
    "grantFindsOut={}\n",
    "\n",
    "# iterate through the keywords\n",
    "for iKeywords in keywords:\n",
    "    # create a blank list to store the IDs of the grants with the keyword in the description\n",
    "    grantsFound=[]\n",
    "    compiledSearch=re.compile('\\\\b'+iKeywords.lower()+'\\\\b')\n",
    "    for iListing in govGrantData_dictionary['Grants']['OpportunitySynopsisDetail_1_0']:\n",
    "        # maybe it doesn't have a description field\n",
    "        try:\n",
    "            # case insensitive regex search find for the keyword\n",
    "            if bool(compiledSearch.search(iListing['Description'].lower().replace('-',''))):\n",
    "                #append the ID if found\n",
    "                grantsFound.append(iListing['OpportunityID'])\n",
    "        except:\n",
    "            # do nothing, if there's no description field, then the word can't be found\n",
    "            pass\n",
    "            \n",
    "    # store the found entries in the output dictionary.  Use the keyword as the key (with spaces replaced with underscores),\n",
    "    # and the value being the list of grant IDs\n",
    "    grantFindsOut[iKeywords.replace(' ','_')]=grantsFound\n",
    "\n",
    "# no need to save it\n",
    "\n",
    "import numpy as np\n",
    "def getGrantAgencies(listOfGrantStrucs):\n",
    "    # generate a vector for the agency names\n",
    "    agencyNameVec=[[] for iGrant in range(len(listOfGrantStrucs)) ]\n",
    "    # iterate through the grants\n",
    "    for iIndex,iListing in enumerate(listOfGrantStrucs):\n",
    "        # this time we're just getting the relevant agency label\n",
    "        # yes, we're redoing what occured in the previous block\n",
    "        # why are you like this government agencies\n",
    "        try:    \n",
    "        # in the normal case\n",
    "            nameHold=iListing['AgencyCode'].split('-')[0]\n",
    "            # set it in the corresponding item in the list\n",
    "            agencyNameVec[iIndex]=nameHold\n",
    "        except:\n",
    "            try:\n",
    "                # if its not there, get the full name\n",
    "                agencyName=iListing['AgencyName']\n",
    "                # and extract the capital letters\n",
    "                nameHold=([char for char in agencyName if char.isupper()])\n",
    "                # set it in the corresponding item in the list\n",
    "                agencyNameVec[iIndex]=nameHold\n",
    "            except:\n",
    "                # well, if you can't adhere to a formatting standard, then you get lumped into other\n",
    "                nameHold='other'\n",
    "                # set it in the corresponding item in the list\n",
    "                agencyNameVec[iIndex]=nameHold\n",
    "    return agencyNameVec\n",
    "\n",
    "def getGrantValues(listOfGrantStrucs):\n",
    "    grantValVec=[[] for iGrant in range(len(listOfGrantStrucs)) ]\n",
    "    for iIndex,iListing in enumerate(listOfGrantStrucs):\n",
    "        try:\n",
    "            # if you can find the expected program funding value, add it to vector while forcing the string to an int\n",
    "            grantValVec[iIndex]=np.int64(iListing['EstimatedTotalProgramFunding'])   \n",
    "        except:\n",
    "            # if you can't\n",
    "            try:\n",
    "                # try and infer a value, if the data is avaialble\n",
    "                # do this by estimating the mean grant value, and multiplying by the expected number of grant awards\n",
    "                totalAvgValue=np.multiply(np.divide((np.int64(iListing['AwardCeiling'])+int(iListing['AwardFloor'])),2),iListing['ExpectedNumberOfAwards'])\n",
    "                # add that value to the val vec\n",
    "                grantValVec[iIndex]=totalAvgValue\n",
    "            except:\n",
    "                # just add zero, as a place holder\n",
    "                grantValVec[iIndex]=np.int64(0)\n",
    "    return grantValVec\n",
    "\n",
    "def getGrantIDs(listOfGrantStrucs):\n",
    "    #extremely simple\n",
    "    grantIDsVec=[iGrant['OpportunityID'] for iGrant in govGrantData_dictionary['Grants']['OpportunitySynopsisDetail_1_0']]\n",
    "    return grantIDsVec\n",
    "\n",
    "grantAgencies=getGrantAgencies(govGrantData_dictionary['Grants']['OpportunitySynopsisDetail_1_0'])\n",
    "grantIDs=getGrantIDs(govGrantData_dictionary['Grants']['OpportunitySynopsisDetail_1_0'])\n",
    "grantAgenciesUnique=np.unique(grantAgencies)\n",
    "#create dictionary holder\n",
    "dataHolder={}\n",
    "\n",
    "#create a dataframe\n",
    "#grantIDsDF=pd.DataFrame(data=blankData,columns=grantAgenciesUnique,index=list(grantFindsOut.keys()),dtype=object)\n",
    "#grantHoldStruc=np.zeros((len(grantAgenciesUnique),len(list(grantFindsOut.keys()))))\n",
    "for matrix_keywordIndex, iKeywords in enumerate(keywords):\n",
    "    currentGrants=grantFindsOut[iKeywords.replace(' ','_')]\n",
    "    for iCurrentGrants in currentGrants:\n",
    "        #find out what it's index is\n",
    "        currentGrantIndex=grantIDs.index(iCurrentGrants)\n",
    "        #find out what agency that is\n",
    "        currentAgency=grantAgencies[currentGrantIndex]\n",
    "        #place it in the dataframe\n",
    "        matrix_agencyIndex=list(grantAgenciesUnique).index(currentAgency)\n",
    "        #(row, column)\n",
    "        #grantIDsDF.loc[currentAgency,iKeywords]=grantIDsDF.loc[iKeywords,currentAgency].append(iCurrentGrants)\n",
    "        tupleKey=tuple([currentAgency,iKeywords])\n",
    "        #if it's not there, make it a blank\n",
    "        if not tupleKey in list(dataHolder.keys()):\n",
    "            dataHolder[tupleKey]=[]\n",
    "            \n",
    "        dataHolder[tupleKey].append(iCurrentGrants)\n",
    "\n",
    "# create a count matrix\n",
    "countMatrix=np.zeros([len(keywords),len(grantAgenciesUnique)])\n",
    "for matrix_keywordIndex, iKeywords in enumerate(keywords):\n",
    "    for matrix_agencyIndex, iAgency in enumerate(grantAgenciesUnique):\n",
    "        tupleKey=tuple([iAgency,iKeywords])\n",
    "        #try and index into it\n",
    "        try:\n",
    "            currVal=len(dataHolder[tupleKey])\n",
    "        except:\n",
    "        #if it's not there, then there aren't any grants in that cell\n",
    "            currVal=0\n",
    "        countMatrix[matrix_keywordIndex,matrix_agencyIndex]=currVal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9866880d",
   "metadata": {},
   "source": [
    "### A small wait\n",
    "\n",
    "Because the previous analysis isn't coded particularly efficient, it can take a moment to complete.  Part of this has to do with the inefficiency required to index back in to the database, as well as the inefficient storage method for the information we are getting (i.e. appending to lists in a large dictionary)\n",
    "\n",
    "In any case, once we have the relevant data structure we can look at which agencies are using which terms, and also receive an ouput of the [grants.gov](https://www.grants.gov/web/grants) IDs associated with those grants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5e879cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbullock\\Anaconda3\\lib\\site-packages\\traitlets\\traitlets.py:588: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  silent = bool(old_value == new_value)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9bc0c1f71d54c77bee96ac8814de4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Row:', options=('replication crisis', 'methodology', 'preregistratâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update_plots(rowSelectName, columnSelectName)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat-davinci-002 prompt\n",
    "# an iteractive jupyer notebook widget that returns two subplot windows.  The input is a numerical matrix.  The interface features two dropdown menus that allow you to select a row (i) and column (j) from the matrix.  On the left side of the subplot outputs, a matrix heatmap plotting the numerical data.  On the right side of the subplot outputs, a blank plot that is used to display text indicating the value found in the specific matrix (i,j) entry selected in the dropdown menus.\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "def heatmap_plot(matrix, heatmap_ax, row, column):\n",
    "    \"\"\"\n",
    "    Plots the heatmap with a crosshair at the desired location\n",
    "    \"\"\"\n",
    "    # if row is empty, default to column\n",
    "    if row == '':\n",
    "        row = column\n",
    "    # if column is empty, default to row\n",
    "    if column == '':\n",
    "        column = row\n",
    "    # if both are empty, no outline\n",
    "    if row == '' and column == '':\n",
    "        row = 0\n",
    "        column = 0\n",
    "    # if both are not empty, only highlight the relevant cell\n",
    "    if row != '' and column != '':\n",
    "        row = row\n",
    "        column = column\n",
    "    # create the heatmap plot\n",
    "    sns.heatmap(matrix, ax=heatmap_ax, norm=LogNorm(), cmap='viridis', cbar=True, xticklabels=list(grantAgenciesUnique) , yticklabels=list(keywords))\n",
    "    # create the outline\n",
    "    heatmap_ax.axvline(x=column+.5, color='red', linewidth=2)\n",
    "    heatmap_ax.axhline(y=row+.5, color='red', linewidth=2)\n",
    "    # show the plot\n",
    "\n",
    "def plot_list(axis, list_of_text, font_size=None, font_color='black', font_family='sans-serif') :\n",
    "    \"\"\"\n",
    "    A function for plotting a list of text elements evenly across a passed in axis.  The function begins by taking in the passed in axis and measuring the space available.  The function then uses those dimensions to determine both the font size and how the list elements should be split into rows and columns so as to take up the maximum amount of space available within the axis, without overlapping.  The function then plots those list elements to the axis space.  Finally the plot is displayed.  The function does not alter the size of the input axes or resultant figure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    axis : matplotlib.axes.Axes\n",
    "        The axis to plot the list of text elements to.\n",
    "    list_of_text : list\n",
    "        A list of text elements to plot to the axis.\n",
    "    font_size : int, optional\n",
    "        The font size to use for the text elements.  If not passed in, the function will calculate the font size based on the size of the axis.\n",
    "    font_color : str, optional\n",
    "        The color of the text elements.  The default is 'black'.\n",
    "    font_family : str, optional\n",
    "        The font family to use for the text elements.  The default is 'sans-serif'.\n",
    "\n",
    "    testBox:\n",
    "    \n",
    "    aaaaa\n",
    "    aaaaa\n",
    "    aaaaa\n",
    "    \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    import math\n",
    "\n",
    "\n",
    "    # get the axis dimensions\n",
    "    #first get the figure handle\n",
    "    fig=axis.get_figure()\n",
    "    bbox = axis.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "    axis_width, axis_height = bbox.width, bbox.height\n",
    "    # returns in pixels, for some reason\n",
    "    #axis_width = axis.get_window_extent().width\n",
    "    #axis_height = axis.get_window_extent().height\n",
    "\n",
    "    # no need to get units for these axes sizes as we can safely assume they are in inches.\n",
    "    spaceNum=4\n",
    "\n",
    "    #assumed aspect ratio, how many characters can you fit along x amount of space vertically : horizontally; see text box for demo\n",
    "    textAspectRatio=5/5\n",
    "    \n",
    "    # calculate the maximum number of characters in the text elements and use this to establish the expected character width of columns\n",
    "    max_characters = max([len(x) for x in list_of_text])\n",
    "\n",
    "    # create a list of spaces to add to the end of each list element\n",
    "    spaces = [' ' * (max_characters - len(x)) for x in list_of_text]\n",
    "\n",
    "    # join the list of text elements with the list of spaces\n",
    "    list_of_text = [x + y for x, y in zip(list_of_text, spaces)]\n",
    "\n",
    "    nonSpaceCount=len(list_of_text) - list_of_text.count(' ')\n",
    "    spacaceCount=list_of_text.count(' ')\n",
    "    #estimate total character footprint\n",
    "    charFootprint=nonSpaceCount+(spacaceCount/2)\n",
    "    #quasi math: rows=3/5*cols; squareform=cols^2; totalChars=(3/5*cols)*cols\n",
    "    colNum=math.ceil(math.sqrt(charFootprint*5/3))\n",
    "    rowNum=math.ceil(colNum*(textAspectRatio))\n",
    "    \n",
    "    #element_per_row=math.ceil(colNum/(max_characters+2))\n",
    "    #get the nearest root that's equal to or greter than len(list_of_text) root\n",
    "    math.ceil(charFootprint/rowNum)\n",
    "\n",
    "    mergedText=''\n",
    "    # conditional appending\n",
    "    for iTextIndex, iTextElements in enumerate(list_of_text):\n",
    "        #if it's divisible by the number of elements per row\n",
    "        if (iTextIndex+1) % math.ceil(charFootprint/rowNum) == 0:\n",
    "            mergedText=mergedText + iTextElements + '\\n'\n",
    "        else:\n",
    "            mergedText=mergedText + iTextElements + spaceNum * ' '\n",
    "\n",
    "    #how many chars per row, spaces only count as half, it seems\n",
    "    #rowCharNumber= (rows_element_num * (max_characters  + math.ceil(spaceNum/2)))-math.ceil(spaceNum/2)  \n",
    "\n",
    "    #72 seems to not actuall be = to one inch\n",
    "    fontScaleFactor=.3\n",
    "\n",
    "    # calculate the maximum allowable font size based on the both the height and width axes, such that no text from list_of_text will exceed the axes boundaries.  Assume 1 point of font is equal to 1/72 inches.\n",
    "    maxWidthFont=(axis_width / (colNum / (72 * fontScaleFactor)))\n",
    "    maxHeightFont=(axis_height /( rowNum / (32* fontScaleFactor)))\n",
    "    max_font_size = min([maxWidthFont, maxHeightFont])\n",
    "\n",
    "    # if a font size was passed in, use it.  Otherwise, use the calculated font size.\n",
    "    if font_size is None :\n",
    "        font_size = max_font_size\n",
    "\n",
    "    # plot the list of text elements to the axis\n",
    "    axis.text(0, 0, mergedText, fontsize=font_size, color=font_color, family=font_family)\n",
    "\n",
    "    # display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# create a function that updates the heatmap\n",
    "def heatmap_and_text(countMatrix,rowSelect,columnSelect):\n",
    "    \"\"\"\n",
    "    Plots both the heatmap and the textbox of grants in a 1 by 2 subplot\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(10, 20))\n",
    "\n",
    "    # plot the heatmap\n",
    "    heatmap_plot(countMatrix, heatmap_ax=plt.gcf().get_axes()[0], row=rowSelect, column=columnSelect)\n",
    "    keyTuple=tuple([col_menu.value,row_menu.value])\n",
    "    try:\n",
    "        list_to_plot=dataHolder[keyTuple]\n",
    "    except:\n",
    "        list_to_plot=['No grants found']\n",
    "    plot_list(plt.gcf().get_axes()[1],list_to_plot)\n",
    "    # show the plot\n",
    "\n",
    "def update_plots(rowSelectName,columnSelectName):\n",
    "    \"\"\"\n",
    "    Performs the updating\n",
    "    \"\"\"\n",
    "    \n",
    "    rowIndex=keywords.index(rowSelectName)\n",
    "    colIndex=list(grantAgenciesUnique).index(columnSelectName)\n",
    "    heatmap_and_text(countMatrix,rowIndex,colIndex)\n",
    "    \n",
    "    \n",
    "# link the dropdown menus to the update functions\n",
    "#row_menu.observe(update_heatmap, names='value')\n",
    "#col_menu.observe(update_heatmap, names='value')\n",
    "# display the widgets\n",
    "#display(row_menu)\n",
    "#display(col_menu)\n",
    "\n",
    "# update the heatmap\n",
    "#update_heatmap(None)\n",
    "# create a dropdown menu for the rows\n",
    "row_menu = widgets.Dropdown(\n",
    "    options=keywords,\n",
    "    #value=,\n",
    "    description='Row:',\n",
    "    disabled=False,\n",
    ")\n",
    "# create a dropdown menu for the columns\n",
    "col_menu = widgets.Dropdown(\n",
    "    options=grantAgenciesUnique,\n",
    "    #value='',\n",
    "    description='Column:',\n",
    "    disabled=False,\n",
    "    )\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact\n",
    "#establishes interactivity\n",
    "interact(update_plots,rowSelectName=row_menu,columnSelectName=col_menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe96528",
   "metadata": {},
   "source": [
    "### Interacting with the plot \n",
    "\n",
    "The widget should allow you to select which terms to work with.  For the moment (i.e. early stages of this notebook) the interaface is relatively rudamentary but the heatmap plot should feature a crosshair indicating which agency and term you are looking at.  The plot beneath that should inclde a list of the grant.gov IDs.  In many cases no grants are found meeting the criteria, and so a large text indicator should appear stating this.  However in the event that grants are found, they should be listed.  Currently the text scaling for this feature is rudamentary, and so if too many are found their font might be extremely small (future [modifications](https://stackoverflow.com/questions/55729075/matplotlib-how-to-autoscale-font-size-so-that-text-fits-some-bounding-box) could adress this).  Additionally, the text elements themselves may be [capable of being hyperlinks](https://matplotlib.org/stable/gallery/misc/hyperlinks_sgskip.html).\n",
    "\n",
    "In any case, we can also attempt to replicate this process and look at the value of the grants as well.  As before, this computation will take a moment.\n",
    "\n",
    "Specific to the plot itself, it's clear to see that the inclusion of \"R\" is throwing off the analysis.  This is likely because the search is returning any instance of the letter R, independent of any relevance to R, the analysis program.  One way to eal with this would be to alter the search to make use of regex and [word boundaries](https://www.regular-expressions.info/wordboundaries.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70736450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now do it again with value\n",
    "\n",
    "#get the values\n",
    "allGrantVals=getGrantValues(govGrantData_dictionary['Grants']['OpportunitySynopsisDetail_1_0'])\n",
    "\n",
    "# create a count matrix\n",
    "valueMatrix=np.zeros([len(keywords),len(grantAgenciesUnique)])\n",
    "for matrix_keywordIndex, iKeywords in enumerate(keywords):\n",
    "    for matrix_agencyIndex, iAgency in enumerate(grantAgenciesUnique):\n",
    "        tupleKey=tuple([iAgency,iKeywords])\n",
    "        #try and index into it\n",
    "        try:\n",
    "            currentGrants=dataHolder[tupleKey]\n",
    "        except:\n",
    "        #if it's not there, then there aren't any grants in that cell\n",
    "            currentGrants=[]\n",
    "            \n",
    "        for iGrants in currentGrants:\n",
    "            #find the ID index\n",
    "            currentAllIndex=grantIDs.index(iGrants)\n",
    "            #find the value associated with this index\n",
    "            currentGrantValue=allGrantVals[currentAllIndex]\n",
    "            #add it to the matrix\n",
    "            valueMatrix[matrix_keywordIndex,matrix_agencyIndex]=valueMatrix[matrix_keywordIndex,matrix_agencyIndex]+currentGrantValue\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ca2016",
   "metadata": {},
   "source": [
    "### Plotting the values\n",
    "\n",
    "We'll reuse much of the same code as we did before, except this tiem we'll be redfining the section where we took in the count matrix.  The interactivity of the resulting plot should be quite the same as the previous one.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804acdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set 0 to nan in the plot to avoid bad log color issues\n",
    "valueMatrix[valueMatrix==0]=np.nan \n",
    "\n",
    "def update_plots(rowSelectName,columnSelectName):\n",
    "    \"\"\"\n",
    "    Performs the updating\n",
    "    \"\"\"\n",
    "    \n",
    "    rowIndex=keywords.index(rowSelectName)\n",
    "    colIndex=list(grantAgenciesUnique).index(columnSelectName)\n",
    "    heatmap_and_text(valueMatrix,rowIndex,colIndex)\n",
    "    \n",
    "# update the heatmap\n",
    "#update_heatmap(None)\n",
    "# create a dropdown menu for the rows\n",
    "row_menu = widgets.Dropdown(\n",
    "    options=keywords,\n",
    "    #value=,\n",
    "    description='Row:',\n",
    "    disabled=False,\n",
    ")\n",
    "# create a dropdown menu for the columns\n",
    "col_menu = widgets.Dropdown(\n",
    "    options=grantAgenciesUnique,\n",
    "    #value='',\n",
    "    description='Column:',\n",
    "    disabled=False,\n",
    "    )\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact\n",
    "#establishes interactivity\n",
    "interact(update_plots,rowSelectName=row_menu,columnSelectName=col_menu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
